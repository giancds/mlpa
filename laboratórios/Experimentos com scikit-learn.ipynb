{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Objetivo\n",
    "\n",
    "A intenção deste exercício é aprender alguns recursos avançados do scikit-learn, especialmente como utilizar *Cross validation*, *Feature Selection* e *Grid Search* para otimizar os hyperparâmetros/features do modelo. Também vamos utilizar este exercício para nos familiarizarmos com as métricas padrão de avaliação de resultados.\n",
    "\n",
    "\n",
    "\n",
    "## 2 - Carregando as bibliotecas\n",
    "\n",
    "Mais uma vez vamos utilizar o Scikit-learn. Devido a sua facilidade de utilização e métodos pré-implementados é fácil ver o motivo de ter se tornado padrão na indústria de tecnologia.\n",
    "\n",
    "Para utilizá-la, vamos primeiro carregar os métodos/módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # primeiro importamos a biblioteca para visualização\n",
    "import numpy as np  # importamos também a biblioteca NumPy que irá nos fornecer diversos métodos para trabalhar com arrays\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Funções auxiliares\n",
    "\n",
    "De maneira geral, os algoritmos de machine learning precisam de features numéricas. Por isso, precisamos converter as features que estão em formato textual para um formato mais apropriado. A função abaixo faz isso utilizando uma função pré-implementada pela biblioteca ```pandas```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_categorias(df):\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    # job\n",
    "    df.job = pd.Categorical(df.job)\n",
    "    df['job'] = df.job.cat.codes\n",
    "    # marital\n",
    "    df.marital = pd.Categorical(df.marital)\n",
    "    df['marital'] = df.marital.cat.codes\n",
    "    # education\n",
    "    df.education = pd.Categorical(df.education)\n",
    "    df['education'] = df.education.cat.codes\n",
    "    # default\n",
    "    df.default = pd.Categorical(df.default)\n",
    "    df['default'] = df.default.cat.codes\n",
    "    # housing\n",
    "    df.housing = pd.Categorical(df.housing)\n",
    "    df['housing'] = df.housing.cat.codes\n",
    "    # loan\n",
    "    df.loan = pd.Categorical(df.loan)\n",
    "    df['loan'] = df.loan.cat.codes\n",
    "    # contact\n",
    "    df.contact = pd.Categorical(df.contact)\n",
    "    df['contact'] = df.contact.cat.codes\n",
    "    # month\n",
    "    df.month = pd.Categorical(df.month)\n",
    "    df['month'] = df.month.cat.codes\n",
    "    # outcome\n",
    "    df.poutcome = pd.Categorical(df.poutcome)\n",
    "    df['poutcome'] = df.poutcome.cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Dataset\n",
    "\n",
    "O dataset que vamos utilizar aqui foi disponibilizado para o *UCI Machine Learning repository* por Moro et al., 2014 [1]. Este é um dataset criado para uma campanha de marketing bancário em 2011. Para mais detalhes sobre o dataset, acesse [este link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).\n",
    "\n",
    "*Observação*: O *UCI Machine Learning repository* é o maior repositório de datasets para experimentos com Machine Learning. Ele contém centenas de datasets para download assim como as fontes que os construíram. Desta forma, podemos comparar a performance dos nossos experimentos com a performance obtida pelos criadores do dataset. É um excelente lugar para praticar nossas habilidades com o machine learning.\n",
    "\n",
    "\n",
    "Abaixo nós utilizamos a biblioteca ```pandas``` para criar um objeto ```DataFrame``` contendo os datapoints.\n",
    "\n",
    "<sup>[1] S. Moro, P. Cortez and P. Rita. *A Data-Driven Approach to Predict the Success of Bank Telemarketing*. Decision Support Systems, Elsevier, 62:22-31, June 2014</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"data/trainset.csv\")\n",
    "testset = pd.read_csv(\"data/testset.csv\")\n",
    "\n",
    "X_train = trainset.loc[:, trainset.columns != \"y\"]\n",
    "y_train = trainset.loc[:, trainset.columns == \"y\"]\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "\n",
    "X_test = testset.loc[:, testset.columns != \"y\"]\n",
    "y_test = testset.loc[:, testset.columns == \"y\"]\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devemos sempre visualizar os nossos datapoints para termos uma ideia de com o que estamos lidando. No nosso caso, vamos utilizar uma classe da biblioteca ```seaborn``` para criar os gráficos. Entretanto, na maioria dos casos o tamanho do dataset torna proibitivo o uso de algumas funções auxiliares das bibliotecas de visualização e devemos criar os gráficos de forma independente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(trainset, diag_kind='kde', hue=\"y\")  # o parametro 'hue' diz qual coluna contém o alvo para distribuir as cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1 - Convertendo as features\n",
    "\n",
    "Como mencionado anteriormente, alguns algoritmos de machine learning precisam que as features estejam em formato numérico. Abaixo utilizamos a função que criamos no início do exercício para realizar a conversão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = converte_categorias(X_train)\n",
    "X_test = converte_categorias(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Experimentos\n",
    "\n",
    "Feita a conversão das features é hora de realizarmos nossos experimentos.\n",
    "\n",
    "#### 4.1 - Carregando as bibliotecas necessárias\n",
    "\n",
    "Como mencionado anteriormente, o ScikitLearn possui diversas funções auxiliares para realizarmos experimentos e encontrar o melhor modelo para uma determinada tarefa. Abaixo nós importaremos as funções relevantes e um algoritmo para realizarmos experimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Buscando os melhores hyperparâmetros \n",
    "\n",
    "Agora que as funções estão carregadas, vamos testá-las e gerar o melhor resultado possível para nossa tarefa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3  # precisa ser maior que 2\n",
    "\n",
    "# aqui nós criamos um objeto dicionário com o nome do hyperparâmetro e os possíveis valores que ele pode assumir\n",
    "# os hyperparâmetros são específicos para cada algoritmo! Note como neste caso nós chamamos a classe do algoritmo\n",
    "# sem passarmos os hyperparâmetros default\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    \"n_neighbors\": [2, 3, 5, 10],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "# O scikit learn e uma biblioteca bastante flexível. Com poucas linhas de código, podemos executar o mesmo experimento\n",
    "# para diversos algoritmos: basta criar uma lista contendo os algoritmos e uma segunda lista contendo os \n",
    "# dicionários de hyperparâmetros. Detalhe: a ordem das listas é importante!\n",
    "classifiers = [knn]\n",
    "grids = [knn_params]\n",
    "\n",
    "# gera uma lista de tuplas entre classifiers e grids para que cada um fique na\n",
    "# posição correta [(class.1, parms.1), (class.2, params.2), ...]\n",
    "grid_params = zip(classifiers, grids)\n",
    "\n",
    "# aqui fazemos a busca - neste caso a busca é por força bruta, ou seja, vai\n",
    "# testar todas as combinações que incluirmos no dicionário de parâmetros - há\n",
    "# também a opção de se buscar randomicamente, mas precisariamos definir\n",
    "# distribuições ao invés de parâmetros e os resultados são parecidos.\n",
    "# a busca vai ser feita pelo ``score'' que definirmos\n",
    "\n",
    "for _, (classifier, params) in enumerate(grid_params):\n",
    "\n",
    "    print(\"Buscando para aloritmo: {0}\\n\".format(classifier.__class__))\n",
    "\n",
    "    clf = GridSearchCV(estimator=classifier,  # algoritmo em teste\n",
    "                               param_grid=params,  # parâmetros de busca\n",
    "                               cv=folds,  # objeto que vai gerar as divisões\n",
    "                               n_jobs=-1,\n",
    "                               scoring='accuracy')  # score que será utilizado\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "    # aqui nós imprimimos o resultado - o método report vai imprimir as ``top''\n",
    "    # melhores combinações encontrada na busca. Os parâmetros impressos\n",
    "    # são aqueles que teríamos que usar para gerar o classificador de forma isolada\n",
    "    print(\"Melhor seleção de hyperparâmetros:\\n\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\nScores (% de acertos) nos folds de validação:\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"{:.3f} (+/-{:.3f}) for {}\".format(mean, std * 2, params))\n",
    "\n",
    "    print(\"\\nResultado detalhado para o melhor modelo:\\n\")\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe a variação em cada um dos folds do experimento. Esta ocorrência deve-se ao fato de termos um dataset bastante diverso. Isso demonstra a importância de realizarmos o *Cross Validation* para termos uma ideia melhor do comportamento do algoritmo!\n",
    "\n",
    "### 5 - Exercícios\n",
    "\n",
    "#### 5.1 - Experimentando com outros algoritmos\n",
    "\n",
    "Agora que vimos como funciona, vamos experimentar outros algoritmos. Verifique na [documentação do ScikitLearn](http://scikit-learn.org/stable/modules/classes.html) e tente otimizar hyperparâmetros de outros algoritmos. Na célula de código do ítem 4.1 estão algumas sugestões (em forma de comentário) de algoritmos.\n",
    "\n",
    "Rode experimentos com diferentes algortimos e note como os resultados variam. Note também como alguns algoritmos são mais rápidos para treinar enquanto alguns demoram um pouco mais. Paciência é uma virtude que todo praticante de machine learning deve aprender desde o início!\n",
    "\n",
    "\n",
    "#### 5.2 - Desafio\n",
    "\n",
    "Nesta versão da busca por melhores hyperparâmetros nós deixamos de fora a busca pelo melhor conjunto de features. Modifique o código acima baseando-se na explicação [deste link](http://scikit-learn.org/stable/modules/feature_selection.html) usando o código [deste tutorial](http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py) e implemente a seleção de features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
